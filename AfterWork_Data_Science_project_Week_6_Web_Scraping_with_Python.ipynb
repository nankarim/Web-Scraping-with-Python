{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i5A-UY4Yruf"
      },
      "source": [
        "<font color='#2F4F4F'>To use this notebook on Colaboratory, you will need to make a copy of it. Go to File > Save a Copy in Drive. You can then use the new copy that will appear in the new tab.</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rOdcI2Nzhky"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Web Scraping with Python</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcso2rJCNAGq"
      },
      "source": [
        "## <font color='#2F4F4F'>Prerequisites</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSHljMZTNCRI"
      },
      "source": [
        "# We first import the required libraries\n",
        "# ---\n",
        "#\n",
        "import pandas as pd             # library for data manupation\n",
        "import requests                 # library for fetching a web page \n",
        "from bs4 import BeautifulSoup   # library for extrating contents from a webpage "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRmt1rRHgZRG"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1: Obtaining our Data</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM5TKD-P1h7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df05a82-f33b-4a03-cb24-324d63ffc36b"
      },
      "source": [
        "# PigiaMe: https://www.pigiame.co.ke/it-software-jobs\n",
        "# ---\n",
        "#\n",
        "pigia_me = requests.get('https://www.pigiame.co.ke/it-software-jobs')\n",
        "pigia_me"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfUvfxrD1nQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d271df-ba59-49ae-de66-fe75c7811e06"
      },
      "source": [
        "# MyJobMag: https://www.myjobmag.co.ke/jobs-by-field/information-technology\n",
        "# ---\n",
        "#\n",
        "myjob_mag = requests.get('https://www.myjobmag.co.ke/jobs-by-field/information-technology')\n",
        "myjob_mag\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psWrYhRUQDJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6d928a-970f-4acd-af02-56ae040e2908"
      },
      "source": [
        "# KenyanJob: https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133\n",
        "# ---\n",
        "#\n",
        "kenya_job = requests.get('https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133')\n",
        "kenya_job"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7iRb8U8hHNw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2: Parsing</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXWSK1kD2oeN"
      },
      "source": [
        "# Parsing our document: pigia_me\n",
        "# ---\n",
        "# \n",
        "\n",
        "pigia_me = \"https://www.pigiame.co.ke/it-software-jobs\"\n",
        "response = requests.get(pigia_me)\n",
        "html_content = response.content\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrH9mgR82pzg"
      },
      "source": [
        "# Parsing our document: my_job_mag\n",
        "# ---\n",
        "#  \n",
        "myjob_mag = \"https://www.myjobmag.co.ke/jobs-by-field/information-technology\"\n",
        "response = requests.get(myjob_mag)\n",
        "html_content = response.content\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0x-Wz03QP5O"
      },
      "source": [
        "# Parsing our document: kenyan_job\n",
        "# ---\n",
        "# \n",
        "kenya_job = \"https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133\"\n",
        "response = requests.get(kenya_job )\n",
        "html_content = response.content\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OxuOAIXhPl5"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3: Extracting Required Elements</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2p147_LICKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e35d01-206c-43aa-ea71-2c0767664a9b"
      },
      "source": [
        "# 1. Extracting job titles and links: pigia me\n",
        "# ---\n",
        "# \n",
        "pigia_me = \"https://www.pigiame.co.ke/it-software-jobs\"\n",
        "response = requests.get(pigia_me)\n",
        "html_content = response.content\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "job_listings = soup.find_all('div', class_='product-item')\n",
        "\n",
        "# Create empty lists to store the data\n",
        "job_titles = []\n",
        "job_links = []\n",
        "\n",
        "# Extract the job titles and links from the job listings\n",
        "for job in job_listings:\n",
        "    # Get the job title\n",
        "    job_title = job.find('h4', class_='product-item--title').text.strip()\n",
        "    job_titles.append(job_title)\n",
        "    \n",
        "    # Get the job link\n",
        "    job_link = job.find('a', class_='product-item--link')['href']\n",
        "    job_links.append(job_link)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "pigia_me_df = pd.DataFrame({'job_title': job_titles, 'job_link': job_links})\n",
        "\n",
        "# Preview the data\n",
        "print(pigia_me_df.head())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [job_title, job_link]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNLbrng_3QfA"
      },
      "source": [
        "# 2. Extracting job titles: my_job_mag\n",
        "# ---\n",
        "# \n",
        "myjob_mag = \"https://www.myjobmag.co.ke/jobs-by-field/information-technology\"\n",
        "response = requests.get(myjob_mag)\n",
        "html_content = response.content\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "job_listings = soup.find_all('div', class_='product-item')\n",
        "\n",
        "# Create empty lists to store the data\n",
        "job_titles = []\n",
        "job_links = []\n",
        "\n",
        "# Extract the job titles and links from the job listings\n",
        "for job in job_listings:\n",
        "    # Get the job title\n",
        "    job_title = job.find('h4', class_='product-item--title').text.strip()\n",
        "    job_titles.append(job_title)\n",
        "    \n",
        "    # Get the job link\n",
        "    job_link = job.find('a', class_='product-item--link')['href']\n",
        "    job_links.append(job_link)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "myjob_mag_df = pd.DataFrame({'job_title': job_titles, 'job_link': job_links})\n",
        "\n",
        "# Preview the data\n",
        "print(myjob_mag_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0fQKn63QV0R"
      },
      "source": [
        "# 3. Extracting job titles: kenya_job\n",
        "# ---\n",
        "#\n",
        "kenya_job = \"https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133\"\n",
        "response = requests.get(kenya_job)\n",
        "html_content = response.content\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "job_listings = soup.find_all('div', class_='product-item')\n",
        "\n",
        "# Create empty lists to store the data\n",
        "job_titles = []\n",
        "job_links = []\n",
        "\n",
        "# Extract the job titles and links from the job listings\n",
        "for job in job_listings:\n",
        "    # Get the job title\n",
        "    job_title = job.find('h4', class_='product-item--title').text.strip()\n",
        "    job_titles.append(job_title)\n",
        "    \n",
        "    # Get the job link\n",
        "    job_link = job.find('a', class_='product-item--link')['href']\n",
        "    job_links.append(job_link)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "kenya_job_df = pd.DataFrame({'job_title': job_titles, 'job_link': job_links})\n",
        "\n",
        "# Preview the data\n",
        "print(kenya_job_df.head())\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ePXABAihaKn"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4: Saving our Data</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the scraped contents in a dataframe and preview our data\n",
        "\n",
        "\n",
        "# Set the URLs of the three job websites\n",
        "urls = [\n",
        "    \"https://www.pigiame.co.ke/it-software-jobs\",\n",
        "    \"https://www.myjobmag.co.ke/jobs-by-field/information-technology\",\n",
        "    \"https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133\"\n",
        "]\n",
        "\n",
        "job_titles = []\n",
        "job_links = []\n",
        "\n",
        "# Loop through each URL and scrape the job titles and URLs\n",
        "for url in urls:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    if \"pigiame\" in url:\n",
        "        job_titles += [job.text for job in soup.select(\".product-item-title a\")]\n",
        "        job_links += [job['href'] for job in soup.select(\".product-item-title a\")]\n",
        "    elif \"myjobmag\" in url:\n",
        "        job_titles += [job.text for job in soup.select(\".job-details-container .job-title a\")]\n",
        "        job_links += [job['href'] for job in soup.select(\".job-details-container .job-title a\")]\n",
        "    elif \"kenyajob\" in url:\n",
        "        job_titles += [job.text for job in soup.select(\".job-title a\")]\n",
        "        job_links += [job['href'] for job in soup.select(\".job-title a\")]\n",
        "\n",
        "# Combine the job titles and URLs into a single pandas DataFrame\n",
        "jobs_df = pd.DataFrame({'Job Title': job_titles, 'Job Link': job_links})\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(jobs_df.head())"
      ],
      "metadata": {
        "id": "x7D0741OM9dq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}